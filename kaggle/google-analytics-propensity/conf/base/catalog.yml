# Here you can define all your data sets by using simple YAML syntax.
#
# Documentation for this file format can be found in "The Data Catalog"
# Link: https://kedro.readthedocs.io/en/stable/data/data_catalog.html

train.raw_data:
  type: pandas.CSVDataSet
  filepath: "data/01_raw/ga-customer-revenue-prediction/train_v2.csv"
  load_args:
    sep: ","
    chunksize: 20000


train.intermediate_data:
  type: PartitionedDataSet
  path: "data/02_intermediate/train"
  dataset:
    type: pandas.ParquetDataSet
    save_args:
      compression: "GZIP"
  filename_suffix: ".parquet"

train.schema_imposed_data:
  type: PartitionedDataSet
  path: "data/03_primary/train/schema_impose"
  dataset:
    type: google_analytics_propensity.io.custom_parquet_dataset.CustomParquetDataset
    compression: "zstd"
  filename_suffix: ".parquet"

train.primary_data:
  type: PartitionedDataSet
  path: "data/03_primary/train/clean"
  dataset:
    type: google_analytics_propensity.io.custom_parquet_dataset.CustomParquetDataset
    compression: "zstd"
  filename_suffix: ".parquet"