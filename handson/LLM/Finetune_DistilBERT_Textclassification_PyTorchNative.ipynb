{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b648f8a-550c-4e82-9858-435f898b7c84",
   "metadata": {},
   "source": [
    "## Experiment with using Transformer LM to do sentence classification\n",
    "https://huggingface.co/docs/transformers/en/training#train-with-pytorch-trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcf0035-5c05-4279-9027-408ab8b8e344",
   "metadata": {},
   "source": [
    "1. Finetune a classifier head on top of pretrained BERT (Using Native PyTorch)\n",
    "<!-- 2. Take embeddings from pretrained BERT and train a classifier on top of it. This is not finetuning of BERT since BERT is used only for getting embeddings\n",
    "3. Finetune GPT based LM to classify sentence. -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b64061-83ae-4436-b1e0-fd22aed1d440",
   "metadata": {},
   "source": [
    "- Use pretrained DistilBERT model from HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322555d5-e64f-4774-89ed-c6732bdf7031",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>:root { --jp-notebook-max-width: 100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e9edae-8ee0-4bbb-9fe1-b51d207bb7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522b0ebe-5a60-49e5-b9f7-425430e49f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d04cba-d361-43bc-9ffa-9a338d499c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbbcbb7-5562-4ae5-82c4-5ee102dd17ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertModel, DistilBertConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d1a4ed-a732-47f5-b53f-f61661f8802e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379f8cc2-9734-4ca8-93fc-7de480860016",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c30cf55-2ef0-4261-8eb0-893ae8d11af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38091be-002d-4fea-a6a7-19784cc05d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae9d9da-3a74-4c2c-a365-06394f68e87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd5d504-72f2-4c4a-9e6a-c5ac6aaa7d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18490bd-099e-4e05-a21c-ce0d43f3012d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "from transformers import get_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdc8e87-001b-4b3f-99a1-ba12fe6acfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28319368-ef0a-42cb-9083-50708af618e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6f748e-bab9-4166-a66f-ea17cf2fd858",
   "metadata": {},
   "source": [
    "## 1. Finetune a classifier head on top of pretrained BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2afebe9-60f6-4ac3-8c3d-dd210634db1d",
   "metadata": {},
   "source": [
    "## Load dataset at https://huggingface.co/datasets/stanfordnlp/sst2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a9e45b-7338-4ed1-a957-0a37f9330d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_dataset('stanfordnlp/sst2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e814933d-dd01-4cca-a108-8b96eb763f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"test\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37b73cf-050f-4432-8598-d5a2867bfdd0",
   "metadata": {},
   "source": [
    "DistilBERT is a transformers model, smaller and faster than BERT, which was pretrained on the same corpus in a self-supervised fashion, using the BERT base model as a teacher. It was pretrainined with the following objectives:\n",
    "it was pretrained with three objectives:\n",
    "\n",
    "1. Distillation loss: the model was trained to return the same probabilities as the BERT base model.\n",
    "2. Masked language modeling (MLM): this is part of the original training loss of the BERT base model. When taking a sentence, the model randomly masks 15% of the words in the input then run the entire masked sentence through the model and has to predict the masked words. This is different from traditional recurrent neural networks (RNNs) that usually see the words one after the other, or from autoregressive models like GPT which internally mask the future tokens. It allows the model to learn a bidirectional representation of the sentence.\n",
    "3. Cosine embedding loss: the model was also trained to generate hidden states as close as possible as the BERT base model.\n",
    "\n",
    "https://huggingface.co/distilbert/distilbert-base-uncased"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fcd90c-e795-439d-8925-55bd31c9a995",
   "metadata": {},
   "source": [
    "## Step1: Get tokenizer for specific model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb10f28-f325-47d6-9d62-87e75f0d61f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Based on the name of the model(distilbert), AutoTokenizer automatically instantiates one of the tokenizer classes of the library from a pretrained model vocabulary.\n",
    "## https://huggingface.co/docs/transformers/model_doc/auto#transformers.AutoTokenizer\n",
    "## WordPiece based tokizer\n",
    "## Returns DistilBertTokenizer or DistilBertTokenizerFast based on use_fast=True\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\", use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873b826e-e026-4a53-9abb-6325a45a01e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"tokenizer model_max_length: {tokenizer.model_max_length}\") ## A very large values => unreliable\n",
    "print(f\"tokenizer truncation_side: {tokenizer.truncation_side}\")\n",
    "print(f\"tokenizer padding_side: {tokenizer.padding_side}\") \n",
    "print(f\"tokenizer model_input_names: {tokenizer.model_input_names}\") \n",
    "print(f\"tokenizer bos_token: {tokenizer.bos_token}\") \n",
    "print(f\"tokenizer eos_token: {tokenizer.eos_token}\") \n",
    "print(f\"tokenizer unk_token: {tokenizer.unk_token}\") \n",
    "print(f\"tokenizer sep_token: {tokenizer.sep_token}\") \n",
    "print(f\"tokenizer pad_token: {tokenizer.pad_token}\") \n",
    "print(f\"tokenizer cls_token: {tokenizer.cls_token}\") \n",
    "print(f\"tokenizer mask_token: {tokenizer.mask_token}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3dafb96-b0a3-4759-8a1c-dd672a9ac83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check configuration of pretrained DistilBERT model\n",
    "configuration = DistilBertConfig()\n",
    "print(f\"DistilBERT config: {configuration}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7f5c29-acfe-44e4-9aea-81ed45d2404f",
   "metadata": {},
   "source": [
    "## Added padding=\"max_length\" to ensure that all sentences Pad to a maximum length specified with the argument max_length or to the maximum acceptable input length for the model if that argument is not provided.\n",
    "## https://huggingface.co/docs/transformers/v4.40.1/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__\n",
    "## WE ARE NOT USING DataCollatorWithPadding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5d3dac-af8f-4f4f-8568-393dd98f273a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(df, text_column=\"text\"):\n",
    "    ## truncation=True ensures that sequences to be no longer than DistilBERTâ€™s maximum input length\n",
    "    ## https://huggingface.co/docs/transformers/v4.40.1/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__\n",
    "    ## Added padding=\"max_length\" SINCE WE ARE NOT USING DataCollatorWithPadding\n",
    "    return tokenizer(df[text_column], truncation=True, padding=\"max_length\", max_length=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44c7a7d-166d-41ec-933d-1e440ac83b94",
   "metadata": {},
   "source": [
    "## tokenizer returns input_ids (token id) and attention_mask to be input to model\n",
    " https://huggingface.co/docs/transformers/v4.40.1/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a25897-39ef-45b4-ac95-12adb1f160da",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer(['a stirring , funny and finally transporting re imagining of beauty and the beast and 1930s horror films', 'my name is hardik'], truncation=True, padding=\"max_length\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbcd294-7d7e-4fe2-8187-88a50db94698",
   "metadata": {},
   "source": [
    "## encode returns input_ids\n",
    "https://huggingface.co/docs/transformers/v4.40.1/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccb39ed-6afd-4eb8-9754-1a895d840e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_encoding = tokenizer.encode('A stirring , Funny and finally transporting re imagining of beauty and the beast and 1930s horror films amzertfys', truncation=True, padding=\"max_length\", max_length=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d2819c-9e3a-451f-bca6-107ec1ab976b",
   "metadata": {},
   "source": [
    "## decode converts token/ input_ids to tokens and returns sentences\n",
    "https://huggingface.co/docs/transformers/v4.40.1/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0a747b-2bcd-4211-9656-fe3dc0ebda5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode(sample_encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a228b8eb-c77f-45ec-a531-6de2a4bbdf09",
   "metadata": {},
   "source": [
    "## See the tokenization (Wordpiece result) using convert_ids_to_tokens\n",
    "https://huggingface.co/docs/transformers/v4.40.1/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6051a84d-cede-4f11-9133-319ef6080059",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.convert_ids_to_tokens(sample_encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57cf789-d81e-4c0f-9925-36a08ae9eca4",
   "metadata": {},
   "source": [
    "## Step2: Tokenize the entries in text column to get input_ids(token_ids) and attention masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0832cc6-7533-427f-8d05-b56bb78a3df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenized_dict_list = preprocess_function(df, text_column=\"text\")\n",
    "tokenized_df = df.map(partial(preprocess_function, text_column=\"sentence\"), batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149317fe-f8c3-4f50-9409-0d03cd12f71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_df[\"train\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7e1a9a-9205-4631-a26a-27b729b0854e",
   "metadata": {},
   "source": [
    "### Step 2.1 Remove the text column because the model does not accept raw text as an input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0fa5a6-7fa5-42fd-ad3a-4ee8cd38b27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_df = tokenized_df.remove_columns([\"sentence\", \"idx\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b2cf9e-8616-454f-b710-94c5be272291",
   "metadata": {},
   "source": [
    "### Step 2.2 Rename the label column to labels because the model expects the argument to be named labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47d253f-fdc4-46b8-a2cb-4221152ab857",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_df = tokenized_df.rename_column(\"label\", \"labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17526e3f-3974-4ee7-a45f-049dcfdc49c0",
   "metadata": {},
   "source": [
    "### Step 2.3 Set the format of the dataset to return PyTorch tensors instead of lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07f59eb-1e14-4838-8526-91243fe573ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_df.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a384e100-86de-483d-80b1-81fb020dc04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d544f15b-e76c-454b-91b0-09222aee4357",
   "metadata": {},
   "source": [
    "## Step 3: Prepare data using DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799dd812-8fdd-45a9-9fdb-71b0889a78e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(tokenized_df[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb150aed-8a91-405f-8b6c-9aa90f8cc8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(tokenized_df[\"train\"], shuffle=True, batch_size=8)\n",
    "eval_dataloader = DataLoader(tokenized_df[\"validation\"], shuffle=True,batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0573bc6b-9248-4863-a91e-e88dd0ca70e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Iterate over dataloader\n",
    "dataiter = iter(eval_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3412f995-34c7-4073-aaba-20ff395d8b41",
   "metadata": {},
   "source": [
    "## Step 4: Load model with expected number of labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40b8d04-e20c-4045-a38c-12f93c929ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {0:\"negative\", 1:\"positive\"}\n",
    "label2id = {\"negative\":0, \"positive\":1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833d7bc4-c621-4910-8eca-6ddbf71d91fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## https://github.com/huggingface/transformers/blob/main/src/transformers/models/distilbert/modeling_distilbert.py#L928\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert/distilbert-base-uncased\", num_labels=2, id2label=id2label, label2id=label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ea4160-04b1-4acb-a828-c9ac8f5d267e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Pretrained model with classification head architecture: {model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b89186-334d-4d75-848d-f9f09455356a",
   "metadata": {},
   "source": [
    "## This gives us pretrainined DistilBERT model with untrained classification head."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f115e053-fb79-4b73-999b-56925045a315",
   "metadata": {},
   "source": [
    "## Step5 : Set up Optimizer (AdamW) and scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a548f95-328d-4843-8a05-48580ad89435",
   "metadata": {},
   "outputs": [],
   "source": [
    "## https://huggingface.co/docs/transformers/v4.17.0/en/main_classes/optimizer_schedules#transformers.AdamW\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5, weight_decay=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac12d54e-233a-4fa7-b69c-d56c3af66cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "## model.parameters() gives the parameters of the model that need to be optimized by AdamW\n",
    "for i in model.parameters():\n",
    "    print(i)\n",
    "    print(f\"Shape of tensor: {i.size()}\")\n",
    "    print(\"==========\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c00391-4129-4c07-aa93-fcfa2fb43a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "num_training_steps = num_epochs*len(train_dataloader)\n",
    "print(f\"num_training_steps: {num_training_steps}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d57964f-a10d-404c-8024-25cf6d86016d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scheduler = get_scheduler(name=\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc15ef34-2c50-45f9-827e-dc8c799bfa64",
   "metadata": {},
   "source": [
    "## Step6: Set device to cuda if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599bad6b-0b59-4046-bdd5-ac62c0a57be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d31b68f-ea9e-4bf2-8dc1-f1403086b498",
   "metadata": {},
   "source": [
    "## Step7: Set training loop\n",
    "## Forward pass: https://github.com/huggingface/transformers/blob/main/src/transformers/models/distilbert/modeling_distilbert.py#L928\n",
    "## Very slow on local machine but faster on Colab with T4 GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551b37c0-b652-4caa-816e-2e04979e0a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "progress_bar = tqdm(range(num_training_steps)) ## Set progress bar to track each batch with epoch\n",
    "model.train(mode=True) ## Set model to train mode\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in train_dataloader:\n",
    "        ## Bring tensor to device\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        ## Pass batch through the model in train mode\n",
    "        outputs = model(**batch)\n",
    "        ## Get loss\n",
    "        loss = outputs.loss ## returns CE loss function which is defined at https://github.com/huggingface/transformers/blob/main/src/transformers/models/distilbert/modeling_distilbert.py#L928\n",
    "        \n",
    "        ## loss.backward() computes dloss/dx for every parameter x which has requires_grad=True. These are accumulated into x.grad for every parameter x.\n",
    "        loss.backward() ## https://discuss.pytorch.org/t/what-does-the-backward-function-do/9944: Calculate dF(loss function)/dx to update params\n",
    "\n",
    "        ## optimizer.step updates the value of x using the gradient x.grad. For example, the SGD optimizer performs: x += -lr * x.grad\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        ## optimizer.zero_grad() clears x.grad for every parameter x in the optimizer.\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c9ccd1-1429-4869-a8f4-49cc7d4583a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e11007-adaf-4a2b-bfff-4d926f1eb78d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1092c3-c280-4b46-9e0b-c3038b2c5f8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8ad8fb-8c95-4e94-be14-c34523f57858",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b853cab-0f15-4920-be57-45d2e33ef080",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d5828a-ee97-4416-854a-5322c0f4caef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404b7737-065a-4fe1-833f-1e66f62e1a78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee495b7c-7fee-4ff3-81bd-0158f742631c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bb6539-0726-4c24-a441-e573866c69ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cbbdc99c-1447-4f1c-89d4-72ab590cf332",
   "metadata": {},
   "source": [
    "## Step3: Padd shorted sequences to ensure all are of length 512 tokens (In step 2 we truncated long sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910b3dd5-16b3-4e04-a641-d47c971c0e71",
   "metadata": {},
   "source": [
    "https://huggingface.co/docs/transformers/v4.40.1/en/main_classes/data_collator#transformers.DataCollatorWithPadding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d6a06d-852a-44ee-8f17-0808322a8d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ca0f05-96c3-42b2-b21a-86473081bd8c",
   "metadata": {},
   "source": [
    "## Step 4: Get eveluation metric (scikit learn or evaluate library)\n",
    "https://huggingface.co/docs/evaluate/package_reference/loading_methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd5de39-3889-4eb5-9dd9-9cb17423f571",
   "metadata": {},
   "outputs": [],
   "source": [
    "##evaluate.list_evaluation_modules(module_type=\"metric\", include_community=True, with_details=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12590c2a-9096-4c84-9f66-a3dd176152de",
   "metadata": {},
   "outputs": [],
   "source": [
    "[metric for metric in evaluate.list_evaluation_modules(module_type=\"metric\", include_community=True) if 'f1' in metric]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0e3c8f-ae58-4688-b0a1-d56c1e1a5681",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = evaluate.load(\"accuracy\")\n",
    "precision = evaluate.load(\"precision\")\n",
    "recall = evaluate.load(\"recall\")\n",
    "f1 = evaluate.load(\"f1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90ff801-af18-4a71-8257-15e00acb4f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    accuracy_value = accuracy.compute(predictions=predictions, references=labels)[\"accuracy\"]\n",
    "    precision_value = precision.compute(predictions=predictions, references=labels)[\"precision\"]\n",
    "    recall_value = recall.compute(predictions=predictions, references=labels)[\"recall\"]\n",
    "    f1_value = f1.compute(predictions=predictions, references=labels)[\"f1\"]\n",
    "    return {\"accuracy\": accuracy_value, \"precision\":precision_value, \"recall\":recall_value, \"f1\":f1_value}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68edd58-6fc4-43de-a270-b561e2cb2040",
   "metadata": {},
   "source": [
    "## Step 5: Get id2label and label2id mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6920e15-a790-49ec-97c2-b7249e7f33c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba975b6f-36b4-4a57-801b-c5d8949c6266",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "21b2da3f-c130-45ad-8f6c-93de3678ffc6",
   "metadata": {},
   "source": [
    "## Step 6: Train model\n",
    "1. Use Trainer API by Hugging face which abstracts the training loop\n",
    "2. Manually write training loop in native Pytorch/ Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f5e2d6-a27d-47af-8641-248ed1ea4000",
   "metadata": {},
   "source": [
    "### Step 6.1 Use Trainer API\n",
    "https://huggingface.co/docs/transformers/en/training#train-with-pytorch-trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7678aaf2-1faa-4dfe-bd84-fbdd1c013fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## https://huggingface.co/docs/transformers/v4.40.1/en/model_doc/auto#transformers.AutoModelForSequenceClassification\n",
    "## model with be instantiated with a classification head (Linear+Softmax)\n",
    "## https://huggingface.co/docs/transformers/v4.40.1/en/main_classes/configuration#transformers.PretrainedConfig\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert/distilbert-base-uncased\", num_labels=2, id2label=id2label, label2id=label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd396fb4-bfe6-45c3-98bc-e4381f35b8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Pretrained model with classification head architecture: {model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9f25fb-c03b-4bcf-af6c-692bfd8148cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "##https://huggingface.co/docs/transformers/v4.17.0/en/main_classes/trainer#transformers.TrainingArguments\n",
    "## num_train_epochs,  + arguments to control optimizer like learning rate\n",
    "## Checkpoints are saved every 500 steps since save_strategy=steps and save_steps=500 by default\n",
    "training_arguments = TrainingArguments(output_dir=\"./results\", learning_rate=2e-5, per_device_train_batch_size=16, per_device_eval_batch_size=16, num_train_epochs=5, weight_decay=0.01, evaluation_strategy=\"epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ad812a-8342-4273-a9ce-d46bee39d3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## https://huggingface.co/docs/transformers/v4.17.0/en/main_classes/trainer#transformers.Trainer\n",
    "## INformaitoj like train / val dataset, data_collator, metrics to compute, optimzer and scheduler to use (default:  AdamW with get_linear_schedule_with_warmup())\n",
    "trainer = Trainer(model=model, args=training_arguments, train_dataset=tokenized_df[\"train\"], eval_dataset=tokenized_df[\"validation\"], tokenizer=tokenizer, data_collator=data_collator, compute_metrics=compute_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30467e6-715b-4780-adae-447af5e20a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b0adbf-e77c-4d52-a643-a8cef388e71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a7558d-09fe-41ae-8f0e-9485fd9766bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"./results/finetuned_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018fc876-bac6-4d80-a6db-d7e82ee59996",
   "metadata": {},
   "source": [
    "## Evaluating on validation dataset outside model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f8f1dc-d3ee-44e1-b634-ace2f1742eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate(eval_dataset=tokenized_df[\"validation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4d5c03-3a70-4283-85fe-ec5805b4e842",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_df[\"test\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eada5592-0b5b-45c0-8416-96231311a4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = tokenized_df[\"test\"].remove_columns(\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6b23d9-794f-40a0-92b4-22d04a8b883d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = trainer.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4f695d-44ea-47f0-9ea0-0e73f1ca5f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictions.predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579b42a4-b69b-49be-b2d4-01f2a0021587",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.argmax(predictions.predictions, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c565306a-c2f0-421a-b3a1-4dc951804e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_test_dataset = test_dataset.add_column(\"prediction\", [id2label[pred] for pred in preds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bcb8d5-ba19-4c48-b0a9-d75a0b544ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6384ad9-87c3-4b76-9188-d04bee52ce13",
   "metadata": {},
   "source": [
    "## Load pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1366d0b7-7eea-4d92-aac0-cfb325c8cbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuned_model = AutoModelForSequenceClassification.from_pretrained(\"./results/finetuned_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22de167-469e-4822-b90e-dfa02577f836",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c5e234-b0a8-41a5-87ab-885d2462dd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = pipeline(task=\"text-classification\", model=\"./results/finetuned_model\", device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e22f82-d299-4ff3-8de7-a8da693d88a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf([dd[\"sentence\"] for dd in test_dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc45d96-ab41-4031-b3a7-da2edf7b0ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "[dd[\"sentence\"] for dd in test_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f22f92d-ce8a-40df-8a3a-14485ce3bde5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd5c4b1-8a1e-480d-9d2d-f06e12c242c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166b1ae1-d6da-474f-99f1-80fcec886a53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77394f07-6b75-41f6-971e-9368cd0c37c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8482a876-8713-4c80-ac69-9fd90d8518a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode(tokenizer(['a stirring , funny and finally transporting re imagining of beauty and the beast and 1930s horror films', 'my name is hardik'], truncation=True, padding=\"max_length\")[\"input_ids\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1166613-b86a-443c-9a20-9f9846014a4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "personal_env",
   "language": "python",
   "name": "personal_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
