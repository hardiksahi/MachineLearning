{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b648f8a-550c-4e82-9858-435f898b7c84",
   "metadata": {},
   "source": [
    "## Experiment with using Transformer LM to do sentence classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcf0035-5c05-4279-9027-408ab8b8e344",
   "metadata": {},
   "source": [
    "1. Finetune a classifier head on top of pretrained BERT\n",
    "2. Take embeddings from pretrained BERT and train a classifier on top of it. This is not finetuning of BERT since BERT is used only for getting embeddings\n",
    "3. Finetune GPT based LM to classify sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b64061-83ae-4436-b1e0-fd22aed1d440",
   "metadata": {},
   "source": [
    "- Use pretrained DistilBERT model from HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322555d5-e64f-4774-89ed-c6732bdf7031",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>:root { --jp-notebook-max-width: 100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e9edae-8ee0-4bbb-9fe1-b51d207bb7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522b0ebe-5a60-49e5-b9f7-425430e49f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d04cba-d361-43bc-9ffa-9a338d499c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbbcbb7-5562-4ae5-82c4-5ee102dd17ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertModel, DistilBertConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d1a4ed-a732-47f5-b53f-f61661f8802e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379f8cc2-9734-4ca8-93fc-7de480860016",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c30cf55-2ef0-4261-8eb0-893ae8d11af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38091be-002d-4fea-a6a7-19784cc05d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae9d9da-3a74-4c2c-a365-06394f68e87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28319368-ef0a-42cb-9083-50708af618e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6f748e-bab9-4166-a66f-ea17cf2fd858",
   "metadata": {},
   "source": [
    "## 1. Finetune a classifier head on top of pretrained BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93b924f-331c-4b68-9594-3cbda7196873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = pd.read_csv('https://github.com/clairett/pytorch-sentiment-classification/raw/master/data/SST2/train.tsv', delimiter='\\t', header=None).rename(columns={0: \"text\", 1:\"label\"})\n",
    "# dev_df = pd.read_csv('https://github.com/clairett/pytorch-sentiment-classification/raw/master/data/SST2/dev.tsv', delimiter='\\t', header=None).rename(columns={0: \"text\", 1:\"label\"})\n",
    "# test_df = pd.read_csv('https://github.com/clairett/pytorch-sentiment-classification/raw/master/data/SST2/test.tsv', delimiter='\\t', header=None).rename(columns={0: \"text\", 1:\"label\"})\n",
    "\n",
    "# dev_df.shape\n",
    "\n",
    "# base_url = \"https://github.com/clairett/pytorch-sentiment-classification/raw/master/data/SST2/\"\n",
    "# data = load_dataset(\"csv\", data_files={\"train\": f\"{base_url}train.tsv\", \"validate\": f\"{base_url}dev.tsv\", \"test\": f\"{base_url}test.tsv\"}, delimiter=\"\\t\")\n",
    "\n",
    "# train_df[\"data_type\"] = \"train\"\n",
    "# dev_df[\"data_type\"] = \"dev\"\n",
    "# test_df[\"data_type\"] = \"test\"\n",
    "\n",
    "# df = pd.concat([train_df, dev_df, test_df], axis=0).reset_index(drop=True)\n",
    "\n",
    "# print(f\"Shape of df: {df.shape}\")\n",
    "\n",
    "# df.head()\n",
    "\n",
    "# ## Quite balanced\n",
    "# df[df.data_type =='train'].label.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2afebe9-60f6-4ac3-8c3d-dd210634db1d",
   "metadata": {},
   "source": [
    "## Load dataset at https://huggingface.co/datasets/stanfordnlp/sst2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a9e45b-7338-4ed1-a957-0a37f9330d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_dataset('stanfordnlp/sst2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37b73cf-050f-4432-8598-d5a2867bfdd0",
   "metadata": {},
   "source": [
    "DistilBERT is a transformers model, smaller and faster than BERT, which was pretrained on the same corpus in a self-supervised fashion, using the BERT base model as a teacher. It was pretrainined with the following objectives:\n",
    "it was pretrained with three objectives:\n",
    "\n",
    "1. Distillation loss: the model was trained to return the same probabilities as the BERT base model.\n",
    "2. Masked language modeling (MLM): this is part of the original training loss of the BERT base model. When taking a sentence, the model randomly masks 15% of the words in the input then run the entire masked sentence through the model and has to predict the masked words. This is different from traditional recurrent neural networks (RNNs) that usually see the words one after the other, or from autoregressive models like GPT which internally mask the future tokens. It allows the model to learn a bidirectional representation of the sentence.\n",
    "3. Cosine embedding loss: the model was also trained to generate hidden states as close as possible as the BERT base model.\n",
    "\n",
    "https://huggingface.co/distilbert/distilbert-base-uncased"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fcd90c-e795-439d-8925-55bd31c9a995",
   "metadata": {},
   "source": [
    "## Step1: Get tokenizer for specific model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb10f28-f325-47d6-9d62-87e75f0d61f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Based on the name of the model(distilbert), AutoTokenizer automatically instantiates one of the tokenizer classes of the library from a pretrained model vocabulary.\n",
    "## https://huggingface.co/docs/transformers/model_doc/auto#transformers.AutoTokenizer\n",
    "## WordPiece based tokizer\n",
    "## Returns DistilBertTokenizer or DistilBertTokenizerFast based on use_fast=True\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\", use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873b826e-e026-4a53-9abb-6325a45a01e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"tokenizer model_max_length: {tokenizer.model_max_length}\") ## A very large values => unreliable\n",
    "print(f\"tokenizer truncation_side: {tokenizer.truncation_side}\")\n",
    "print(f\"tokenizer padding_side: {tokenizer.padding_side}\") \n",
    "print(f\"tokenizer model_input_names: {tokenizer.model_input_names}\") \n",
    "print(f\"tokenizer bos_token: {tokenizer.bos_token}\") \n",
    "print(f\"tokenizer eos_token: {tokenizer.eos_token}\") \n",
    "print(f\"tokenizer unk_token: {tokenizer.unk_token}\") \n",
    "print(f\"tokenizer sep_token: {tokenizer.sep_token}\") \n",
    "print(f\"tokenizer pad_token: {tokenizer.pad_token}\") \n",
    "print(f\"tokenizer cls_token: {tokenizer.cls_token}\") \n",
    "print(f\"tokenizer mask_token: {tokenizer.mask_token}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3dafb96-b0a3-4759-8a1c-dd672a9ac83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check configuration of pretrained DistilBERT model\n",
    "configuration = DistilBertConfig()\n",
    "print(f\"DistilBERT config: {configuration}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5d3dac-af8f-4f4f-8568-393dd98f273a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(df, text_column=\"text\"):\n",
    "    ## truncation=True ensures that sequences to be no longer than DistilBERTâ€™s maximum input length\n",
    "    ## https://huggingface.co/docs/transformers/v4.40.1/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__\n",
    "    return tokenizer(df[text_column], truncation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44c7a7d-166d-41ec-933d-1e440ac83b94",
   "metadata": {},
   "source": [
    "## tokenizer returns input_ids (token id) and attention_mask to be input to model\n",
    " https://huggingface.co/docs/transformers/v4.40.1/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a25897-39ef-45b4-ac95-12adb1f160da",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer(['a stirring , funny and finally transporting re imagining of beauty and the beast and 1930s horror films', 'my name is hardik'], truncation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbcd294-7d7e-4fe2-8187-88a50db94698",
   "metadata": {},
   "source": [
    "## encode returns input_ids\n",
    "https://huggingface.co/docs/transformers/v4.40.1/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccb39ed-6afd-4eb8-9754-1a895d840e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_encoding = tokenizer.encode('A stirring , Funny and finally transporting re imagining of beauty and the beast and 1930s horror films amzertfys', truncation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d2819c-9e3a-451f-bca6-107ec1ab976b",
   "metadata": {},
   "source": [
    "## decode converts token/ input_ids to tokens and returns sentences\n",
    "https://huggingface.co/docs/transformers/v4.40.1/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0a747b-2bcd-4211-9656-fe3dc0ebda5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode(sample_encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a228b8eb-c77f-45ec-a531-6de2a4bbdf09",
   "metadata": {},
   "source": [
    "## See the tokenization (Wordpiece result) using convert_ids_to_tokens\n",
    "https://huggingface.co/docs/transformers/v4.40.1/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6051a84d-cede-4f11-9133-319ef6080059",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.convert_ids_to_tokens(sample_encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57cf789-d81e-4c0f-9925-36a08ae9eca4",
   "metadata": {},
   "source": [
    "## Step2: Tokenize the entries in text column to get input_ids(token_ids) and attention masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0832cc6-7533-427f-8d05-b56bb78a3df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenized_dict_list = preprocess_function(df, text_column=\"text\")\n",
    "tokenized_df = df.map(partial(preprocess_function, text_column=\"sentence\"), batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0fa5a6-7fa5-42fd-ad3a-4ee8cd38b27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbdc99c-1447-4f1c-89d4-72ab590cf332",
   "metadata": {},
   "source": [
    "## Step3: Padd shorted sequences to ensure all are of length 512 tokens (In step 2 we truncated long sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910b3dd5-16b3-4e04-a641-d47c971c0e71",
   "metadata": {},
   "source": [
    "https://huggingface.co/docs/transformers/v4.40.1/en/main_classes/data_collator#transformers.DataCollatorWithPadding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d6a06d-852a-44ee-8f17-0808322a8d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ca0f05-96c3-42b2-b21a-86473081bd8c",
   "metadata": {},
   "source": [
    "## Step 4: Get eveluation metric (scikit learn or evaluate library)\n",
    "https://huggingface.co/docs/evaluate/package_reference/loading_methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd5de39-3889-4eb5-9dd9-9cb17423f571",
   "metadata": {},
   "outputs": [],
   "source": [
    "##evaluate.list_evaluation_modules(module_type=\"metric\", include_community=True, with_details=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12590c2a-9096-4c84-9f66-a3dd176152de",
   "metadata": {},
   "outputs": [],
   "source": [
    "[metric for metric in evaluate.list_evaluation_modules(module_type=\"metric\", include_community=True) if 'f1' in metric]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0e3c8f-ae58-4688-b0a1-d56c1e1a5681",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = evaluate.load(\"accuracy\")\n",
    "precision = evaluate.load(\"precision\")\n",
    "recall = evaluate.load(\"recall\")\n",
    "f1 = evaluate.load(\"f1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90ff801-af18-4a71-8257-15e00acb4f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    accuracy_value = accuracy(predictions=predictions, references=labels)\n",
    "    precision_value = precision(predictions=predictions, references=labels)\n",
    "    recall_value = recall(predictions=predictions, references=label)\n",
    "    f1_value = f1(predictions=predictions, references=label)\n",
    "    return accuracy_value, precision_value, recall_value, f1_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68edd58-6fc4-43de-a270-b561e2cb2040",
   "metadata": {},
   "source": [
    "## Step 5: Get id2label and label2id mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6920e15-a790-49ec-97c2-b7249e7f33c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {0:\"negative\", 1:\"positive\"}\n",
    "label2id = {\"negative\":0, \"positive\":1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba975b6f-36b4-4a57-801b-c5d8949c6266",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "21b2da3f-c130-45ad-8f6c-93de3678ffc6",
   "metadata": {},
   "source": [
    "## Step 6: Train model\n",
    "1. Use Trainer API by Hugging face which abstracts the training loop\n",
    "2. Manually write training loop in native Pytorch/ Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f5e2d6-a27d-47af-8641-248ed1ea4000",
   "metadata": {},
   "source": [
    "### Step 6.1 Use Trainer API\n",
    "https://huggingface.co/docs/transformers/en/training#train-with-pytorch-trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7678aaf2-1faa-4dfe-bd84-fbdd1c013fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## https://huggingface.co/docs/transformers/v4.40.1/en/model_doc/auto#transformers.AutoModelForSequenceClassification\n",
    "## model with be instantiated with a classification head (Linear+Softmax)\n",
    "## https://huggingface.co/docs/transformers/v4.40.1/en/main_classes/configuration#transformers.PretrainedConfig\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert/distilbert-base-uncased\", num_labels=2, id2label=id2label, label2id=label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd396fb4-bfe6-45c3-98bc-e4381f35b8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Pretrained model with classification head architecture: {model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9f25fb-c03b-4bcf-af6c-692bfd8148cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "##https://huggingface.co/docs/transformers/v4.17.0/en/main_classes/trainer#transformers.TrainingArguments\n",
    "## num_train_epochs,  learning_rate, optimizer to use\n",
    "training_arguments = TrainingArguments(output_dir=\"./results\", learning_rate=2e-5, per_device_train_batch_size=16, per_device_eval_batch_size=16, num_train_epochs=5, weight_decay=0.01, evaluation_strategy=\"epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ad812a-8342-4273-a9ce-d46bee39d3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## https://huggingface.co/docs/transformers/v4.17.0/en/main_classes/trainer#transformers.Trainer\n",
    "## INformaitoj like train / val dataset, data_collator, metrics to compute\n",
    "trainer = Trainer(model=model, args=training_arguments, train_dataset=tokenized_df[\"train\"], eval_dataset=tokenized_df[\"validation\"], tokenizer=tokenizer, data_collator=data_collator, compute_metrics=compute_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30467e6-715b-4780-adae-447af5e20a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b0adbf-e77c-4d52-a643-a8cef388e71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bbbdbe-0c27-4e48-a4f6-2fc3c1b7ac83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "personal_env",
   "language": "python",
   "name": "personal_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
