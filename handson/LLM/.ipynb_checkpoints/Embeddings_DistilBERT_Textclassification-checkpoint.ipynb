{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b648f8a-550c-4e82-9858-435f898b7c84",
   "metadata": {},
   "source": [
    "## Experiment with using Transformer LM to do sentence classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcf0035-5c05-4279-9027-408ab8b8e344",
   "metadata": {},
   "source": [
    "<!-- 1. Finetune a classifier head on top of pretrained BERT -->\n",
    "Take embeddings from pretrained BERT and train a logistic classifier on top of it. This is not finetuning of BERT since BERT is used only for getting embeddings\n",
    "<!-- 3. Finetune GPT based LM to classify sentence. -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "322555d5-e64f-4774-89ed-c6732bdf7031",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>:root { --jp-notebook-max-width: 100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>:root { --jp-notebook-max-width: 100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8e9edae-8ee0-4bbb-9fe1-b51d207bb7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "522b0ebe-5a60-49e5-b9f7-425430e49f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1d04cba-d361-43bc-9ffa-9a338d499c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afbbcbb7-5562-4ae5-82c4-5ee102dd17ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertModel, DistilBertConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33d1a4ed-a732-47f5-b53f-f61661f8802e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import DataCollatorWithPadding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "379f8cc2-9734-4ca8-93fc-7de480860016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c30cf55-2ef0-4261-8eb0-893ae8d11af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f38091be-002d-4fea-a6a7-19784cc05d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dae9d9da-3a74-4c2c-a365-06394f68e87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0105aa6e-c728-41c7-9551-6fd8a5d0d41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dffc29ab-f66c-41be-bb78-bef5196bd100",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "261c8966-3ad2-411f-963b-fc0f2eb8341a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28319368-ef0a-42cb-9083-50708af618e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6f748e-bab9-4166-a66f-ea17cf2fd858",
   "metadata": {},
   "source": [
    "# Train logistic classifier top of pretrained BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2afebe9-60f6-4ac3-8c3d-dd210634db1d",
   "metadata": {},
   "source": [
    "## Load dataset at https://huggingface.co/datasets/stanfordnlp/sst2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e0a9e45b-7338-4ed1-a957-0a37f9330d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = load_dataset('stanfordnlp/sst2', split=\"train\").shuffle().select(range(5000))\n",
    "validation_df = load_dataset('stanfordnlp/sst2', split=\"validation\")\n",
    "test_df = load_dataset('stanfordnlp/sst2', split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5fb5f2fb-d99d-4bc9-bdb7-7c6a6a33f232",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['idx', 'sentence', 'label'],\n",
       "    num_rows: 1821\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37b73cf-050f-4432-8598-d5a2867bfdd0",
   "metadata": {},
   "source": [
    "DistilBERT is a transformers model, smaller and faster than BERT, which was pretrained on the same corpus in a self-supervised fashion, using the BERT base model as a teacher. It was pretrainined with the following objectives:\n",
    "it was pretrained with three objectives:\n",
    "\n",
    "1. Distillation loss: the model was trained to return the same probabilities as the BERT base model.\n",
    "2. Masked language modeling (MLM): this is part of the original training loss of the BERT base model. When taking a sentence, the model randomly masks 15% of the words in the input then run the entire masked sentence through the model and has to predict the masked words. This is different from traditional recurrent neural networks (RNNs) that usually see the words one after the other, or from autoregressive models like GPT which internally mask the future tokens. It allows the model to learn a bidirectional representation of the sentence.\n",
    "3. Cosine embedding loss: the model was also trained to generate hidden states as close as possible as the BERT base model.\n",
    "\n",
    "https://huggingface.co/distilbert/distilbert-base-uncased"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fcd90c-e795-439d-8925-55bd31c9a995",
   "metadata": {},
   "source": [
    "## Step1: Get tokenizer for specific model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fdb10f28-f325-47d6-9d62-87e75f0d61f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hardiksahi/miniconda3/envs/personal_env/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "## Based on the name of the model(distilbert), AutoTokenizer automatically instantiates one of the tokenizer classes of the library from a pretrained model vocabulary.\n",
    "## https://huggingface.co/docs/transformers/model_doc/auto#transformers.AutoTokenizer\n",
    "## WordPiece based tokizer\n",
    "## Returns DistilBertTokenizer or DistilBertTokenizerFast based on use_fast=True\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\", use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "873b826e-e026-4a53-9abb-6325a45a01e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizer model_max_length: 1000000000000000019884624838656\n",
      "tokenizer truncation_side: right\n",
      "tokenizer padding_side: right\n",
      "tokenizer model_input_names: ['input_ids', 'attention_mask']\n",
      "tokenizer bos_token: None\n",
      "tokenizer eos_token: None\n",
      "tokenizer unk_token: [UNK]\n",
      "tokenizer sep_token: [SEP]\n",
      "tokenizer pad_token: [PAD]\n",
      "tokenizer cls_token: [CLS]\n",
      "tokenizer mask_token: [MASK]\n"
     ]
    }
   ],
   "source": [
    "print(f\"tokenizer model_max_length: {tokenizer.model_max_length}\") ## A very large values => unreliable\n",
    "print(f\"tokenizer truncation_side: {tokenizer.truncation_side}\")\n",
    "print(f\"tokenizer padding_side: {tokenizer.padding_side}\") \n",
    "print(f\"tokenizer model_input_names: {tokenizer.model_input_names}\") \n",
    "print(f\"tokenizer bos_token: {tokenizer.bos_token}\") \n",
    "print(f\"tokenizer eos_token: {tokenizer.eos_token}\") \n",
    "print(f\"tokenizer unk_token: {tokenizer.unk_token}\") \n",
    "print(f\"tokenizer sep_token: {tokenizer.sep_token}\") \n",
    "print(f\"tokenizer pad_token: {tokenizer.pad_token}\") \n",
    "print(f\"tokenizer cls_token: {tokenizer.cls_token}\") \n",
    "print(f\"tokenizer mask_token: {tokenizer.mask_token}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e3dafb96-b0a3-4759-8a1c-dd672a9ac83e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DistilBERT config: DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"transformers_version\": \"4.40.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Check configuration of pretrained DistilBERT model\n",
    "configuration = DistilBertConfig()\n",
    "print(f\"DistilBERT config: {configuration}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ad5d3dac-af8f-4f4f-8568-393dd98f273a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(df, text_column=\"text\"):\n",
    "    ## truncation=True ensures that sequences to be no longer than DistilBERT’s maximum input length\n",
    "    ## https://huggingface.co/docs/transformers/v4.40.1/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.__call__\n",
    "    return tokenizer(df[text_column], truncation=True, padding=\"longest\") ## padding=longest will pad all input sequences in the batch to the length of longest sequence(THIS MIGHT BE LESSER THAN MAX TOKEN COUNT i.e. 512)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44c7a7d-166d-41ec-933d-1e440ac83b94",
   "metadata": {},
   "source": [
    "## tokenizer returns input_ids (token id) and attention_mask to be input to model\n",
    " https://huggingface.co/docs/transformers/v4.40.1/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a1a25897-39ef-45b4-ac95-12adb1f160da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 1037, 18385, 1010, 6057, 1998, 2633, 18276, 2128, 16603, 1997, 5053, 1998, 1996, 6841, 1998, 5687, 5469, 3152, 102], [101, 2026, 2171, 2003, 2524, 5480, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(['a stirring , funny and finally transporting re imagining of beauty and the beast and 1930s horror films', 'my name is hardik'], truncation=True, padding=\"longest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7f4ff681-a2ac-4869-a4d0-325521ffb98a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 1037, 18385, 1010, 6057, 1998, 2633, 18276, 2128, 16603, 1997, 5053, 1998, 1996, 6841, 1998, 5687, 5469, 3152, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 2026, 2171, 2003, 2524, 5480, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(['a stirring , funny and finally transporting re imagining of beauty and the beast and 1930s horror films', 'my name is hardik'], truncation=True, padding=\"max_length\", max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6051a84d-cede-4f11-9133-319ef6080059",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizer.convert_ids_to_tokens(sample_encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57cf789-d81e-4c0f-9925-36a08ae9eca4",
   "metadata": {},
   "source": [
    "## Step2: Tokenize the entries in text column to get input_ids(token_ids) and attention masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f0832cc6-7533-427f-8d05-b56bb78a3df0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb9f78795f264e5aa026015d2e242aa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#tokenized_dict_list = preprocess_function(df, text_column=\"text\")\n",
    "train_tokenized_df = train_df.map(partial(preprocess_function, text_column=\"sentence\"), batched=True)\n",
    "validation_tokenized_df = validation_df.map(partial(preprocess_function, text_column=\"sentence\"), batched=True)\n",
    "test_tokenized_df = test_df.map(partial(preprocess_function, text_column=\"sentence\"), batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a382f2a4-6627-4fd2-a425-5888f73b807d",
   "metadata": {},
   "source": [
    "## This shows that the padding is different for different batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "44925fcf-2b1f-4cb5-a8a7-215c2d164f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_input_id_length = -1\n",
    "min_input_id_length = np.inf\n",
    "\n",
    "for i in train_tokenized_df:\n",
    "    inp_id = i[\"input_ids\"]\n",
    "    ll = len(inp_id)\n",
    "    if ll > max_input_id_length:\n",
    "        max_input_id_length = ll\n",
    "    if ll < min_input_id_length:\n",
    "        min_input_id_length = ll\n",
    "\n",
    "for i in validation_tokenized_df:\n",
    "    inp_id = i[\"input_ids\"]\n",
    "    ll = len(inp_id)\n",
    "    if ll > max_input_id_length:\n",
    "        max_input_id_length = ll\n",
    "    if ll < min_input_id_length:\n",
    "        min_input_id_length = ll\n",
    "\n",
    "for i in test_tokenized_df:\n",
    "    inp_id = i[\"input_ids\"]\n",
    "    ll = len(inp_id)\n",
    "    if ll > max_input_id_length:\n",
    "        max_input_id_length = ll\n",
    "    if ll < min_input_id_length:\n",
    "        min_input_id_length = ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "061786d5-d5e0-4749-a28f-6851af13d92a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_input_id_length: 51, max_input_id_length: 64\n"
     ]
    }
   ],
   "source": [
    "print(f\"min_input_id_length: {min_input_id_length}, max_input_id_length: {max_input_id_length}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db40d3a-0d64-4b6c-8d59-9f52f5878004",
   "metadata": {},
   "source": [
    "## Step 3: Now I have to iterate over the dataset and make sure everything is padded to exact same length = 66 (i.e. longest overall else model will not be able to handle it)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d818ca50-8001-44ac-9ee1-551115c7e037",
   "metadata": {},
   "source": [
    "## Code inspired from https://madewithml.com/courses/mlops/training/#model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ffe291b6-31d2-4d35-9f5a-1aefab0c4535",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_to_max_length(batch, column_name, max_length=max_input_id_length, dtype=np.int32, pad_value=0):\n",
    "    ## UDF toi be used in map function\n",
    "    arr_to_pad = batch[column_name]\n",
    "    row_count = len(arr_to_pad)\n",
    "    padded_arr = np.full((row_count, max_length), fill_value=pad_value, dtype=dtype)\n",
    "    for i, row in enumerate(arr_to_pad):\n",
    "        padded_arr[i][:len(row)] = row\n",
    "    return {column_name: padded_arr.tolist()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "649103f8-d875-4f4e-9628-54b79e90a3e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "080d82b518ef427c8ab923a9c9a67482",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "806928bdacfc4adfae44058403e3df71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Use huggungface map (https://huggingface.co/docs/datasets/v2.19.0/en/package_reference/main_classes#datasets.Dataset.map)\n",
    "train_tokenized_df = train_tokenized_df.map(partial(pad_to_max_length, column_name=\"input_ids\"), batched=True)\n",
    "train_tokenized_df = train_tokenized_df.map(partial(pad_to_max_length, column_name=\"attention_mask\"), batched=True)\n",
    "\n",
    "validation_tokenized_df = validation_tokenized_df.map(partial(pad_to_max_length, column_name=\"input_ids\"), batched=True)\n",
    "validation_tokenized_df = validation_tokenized_df.map(partial(pad_to_max_length, column_name=\"attention_mask\"), batched=True)\n",
    "\n",
    "test_tokenized_df = test_tokenized_df.map(partial(pad_to_max_length, column_name=\"input_ids\"), batched=True)\n",
    "test_tokenized_df = test_tokenized_df.map(partial(pad_to_max_length, column_name=\"attention_mask\"), batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ea984d59-4d10-4b1b-af30-b7195efdcd21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_tokenized_df[1][\"input_ids\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27a05a9-8f41-4e92-b18d-8354e020da10",
   "metadata": {},
   "source": [
    "## Step4: Load pretrained DistilBert model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9e3d740b-d464-46bb-80b9-7616eb2dcafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DistilBertModel.from_pretrained(\"distilbert/distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c1498664-3335-40a4-a859-fdf0f2764949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DistilBertModel(\n",
      "  (embeddings): Embeddings(\n",
      "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "    (position_embeddings): Embedding(512, 768)\n",
      "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (transformer): Transformer(\n",
      "    (layer): ModuleList(\n",
      "      (0-5): 6 x TransformerBlock(\n",
      "        (attention): MultiHeadSelfAttention(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (ffn): FFN(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (activation): GELUActivation()\n",
      "        )\n",
      "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a826a8c7-0f19-4834-a967-7e1edd706346",
   "metadata": {},
   "source": [
    "## STep 5: Remove unnecessary rows tokenized_df = tokenized_df.remove_columns([\"sentence\", \"idx\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "51603b0e-2141-468d-b21f-6df6e509fedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_train_tokenized_df = train_tokenized_df.remove_columns([\"sentence\", \"idx\", \"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "98146987-d46e-4e0f-96e3-fca22928b4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_validation_tokenized_df = validation_tokenized_df.remove_columns([\"sentence\", \"idx\", \"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e54536cc-2b56-4945-92f4-37c5b78060d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_test_tokenized_df = test_tokenized_df.remove_columns([\"sentence\", \"idx\", \"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272ed9ab-30fd-4d13-9478-50efd32a5764",
   "metadata": {},
   "source": [
    "## Set format to pytorch tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a66a76a8-9a26-40a4-8c3c-04166dd9598b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_train_tokenized_df.set_format(\"torch\")\n",
    "filtered_validation_tokenized_df.set_format(\"torch\")\n",
    "filtered_test_tokenized_df.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad383492-d3c3-41fb-9c3e-f3a1781524a5",
   "metadata": {},
   "source": [
    "## Step 6: Prepare data using DataLoader\n",
    "This is not needed since we only need to get embeddings of pretrained model, We do not have to finetune/ train the model on our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ba0b4866-bb25-47cf-88f3-30f332544f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CORRECT BUT UNNECESSARY\n",
    "# train_dataloader = DataLoader(filtered_train_tokenized_df, shuffle=True, batch_size=8)\n",
    "# eval_dataloader = DataLoader(filtered_validation_tokenized_df[\"validation\"], shuffle=True,batch_size=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731b1e19-5061-44ec-b87e-70a0db12cc5e",
   "metadata": {},
   "source": [
    "## Step7: Set device to cuda if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "942eb247-4fb8-4b57-ab21-d8cf6923333b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12d923f-b8f8-4d80-b7fe-5f298f2e0521",
   "metadata": {},
   "source": [
    "## Step 8: Way 1: Get train data pretrained embeddings corresponding to [CLS] token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b52ea8e8-5e23-4ff1-b7ec-92d7874807e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CORRECT BUT UNNECESSARY\n",
    "# progress_bar = tqdm(range(len(train_dataloader)))\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     #train_last_hidden_states = model(input_ids, attention_mask=attention_mask)\n",
    "#     for batch in enumerate(train_dataloader):\n",
    "#         ## Bring tensor to device\n",
    "#         batch = {k: v.to(device) for k, v in batch.items()}\n",
    "#         ## Pass batch through the model in train mode\n",
    "#         outputs = model(**batch)\n",
    "#         progress_bar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bb175ae3-5de8-43a6-a91d-c469170bc3f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101,  2529,  3325,  ...,     0,     0,     0],\n",
       "        [  101,  6649,  5493,  ...,     0,     0,     0],\n",
       "        [  101,  2002,  1005,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [  101,  1037,  3185,  ...,     0,     0,     0],\n",
       "        [  101,  2053,  3815,  ...,     0,     0,     0],\n",
       "        [  101, 17475,  1996,  ...,     0,     0,     0]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_train_tokenized_df[\"input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d8cb7c73-59d2-47d5-8290-2f1a1c30c0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hidden_state(batch):\n",
    "    inputs = {k: torch.tensor(v).to(device) for k,v in batch.items()}\n",
    "    with torch.no_grad():\n",
    "        last_hidden_state = model(**inputs).last_hidden_state\n",
    "\n",
    "    return {\"hidden_state\": last_hidden_state[:,0,:].cpu().numpy()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "546d9257-7ffe-46f2-9866-398ca6df31c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask'],\n",
       "    num_rows: 5000\n",
       "})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_train_tokenized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ccbd90d5-29a8-4a38-90ef-1d1b9d1955b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edfac7fcc4de42df8f3992a2a222380e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qr/cmfkzy495k7b3bn80b7ygs080000gn/T/ipykernel_10899/3368421567.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs = {k: torch.tensor(v).to(device) for k,v in batch.items()}\n"
     ]
    }
   ],
   "source": [
    "train_last_hidden_states = filtered_train_tokenized_df.map(extract_hidden_state, batched=True)\n",
    "validation_last_hidden_states = filtered_validation_tokenized_df.map(extract_hidden_state, batched=True)\n",
    "test_last_hidden_states = filtered_test_tokenized_df.map(extract_hidden_state, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "20bd5c63-17ca-4322-91cf-bfddf686aced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1911, -0.0145, -0.3096,  ..., -0.1753,  0.5269,  0.3486],\n",
       "        [-0.1433, -0.1866,  0.0773,  ..., -0.1666,  0.2274,  0.2909],\n",
       "        [-0.1332, -0.0910, -0.2276,  ...,  0.0641,  0.5383,  0.2201],\n",
       "        ...,\n",
       "        [-0.1054, -0.1327,  0.0182,  ..., -0.1939,  0.2630,  0.1924],\n",
       "        [-0.0829, -0.0046, -0.0758,  ..., -0.1752,  0.3061,  0.2136],\n",
       "        [-0.2615,  0.1163, -0.0217,  ..., -0.1203,  0.1313,  0.3862]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_last_hidden_states[\"hidden_state\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b13d85f7-24ce-4bb5-8a32-1f4947837b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This takes a lot of memory, not possible to do on personal laptop\n",
    "# with torch.no_grad():\n",
    "#     train_last_hidden_states = model(input_ids=filtered_train_tokenized_df[\"input_ids\"], attention_mask=filtered_train_tokenized_df[\"attention_mask\"])\n",
    "#     validation_last_hidden_states = model(input_ids=filtered_validation_tokenized_df[\"input_ids\"], attention_mask=filtered_validation_tokenized_df[\"attention_mask\"])\n",
    "#     test_last_hidden_states = model(input_ids=filtered_test_tokenized_df[\"input_ids\"], attention_mask=filtered_test_tokenized_df[\"attention_mask\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "45e74175-9c48-47c6-926e-38517ceae66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_features = train_last_hidden_states.last_hidden_state[:,0,:].numpy()\n",
    "# validation_features = validation_last_hidden_states.last_hidden_state[:,0,:].numpy()\n",
    "# test_features = test_last_hidden_states.last_hidden_state[:,0,:].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "33e3e76d-1f39-4cf4-a53d-045f0a15cbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = train_last_hidden_states[\"hidden_state\"]\n",
    "validation_features = validation_last_hidden_states[\"hidden_state\"]\n",
    "test_features = test_last_hidden_states[\"hidden_state\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ebcea4c3-59ef-4aab-b45c-5aa00e8a187f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train_features: torch.Size([5000, 768])\n",
      "Shape of validation_features: torch.Size([872, 768])\n",
      "Shape of test_features: torch.Size([1821, 768])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape of train_features: {train_features.shape}\")\n",
    "print(f\"Shape of validation_features: {validation_features.shape}\")\n",
    "print(f\"Shape of test_features: {test_features.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1150b0b0-b4dc-4215-81b3-28dce3078868",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train_tokenized_df[\"label\"]\n",
    "validation_labels = validation_tokenized_df[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "062ba977-ee38-4f7b-8934-570063c57685",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7828ef2c-e98a-45ac-a3ca-59891ff7ae2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hardiksahi/miniconda3/envs/personal_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3d48fea7-8be4-4c27-b984-753e0119d042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8268348623853211"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf.score(validation_features, validation_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6ea93dd2-b1d3-45ab-a70e-ec83729fdc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_prediction = lr_clf.predict(validation_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "59ddad95-0830-4677-ad9d-9f0a05feb548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.8248337028824834\n",
      "recall: 0.8378378378378378\n",
      "f1: 0.8312849162011173\n"
     ]
    }
   ],
   "source": [
    "print(f\"precision: {precision_score(validation_labels, validation_prediction)}\")\n",
    "print(f\"recall: {recall_score(validation_labels, validation_prediction)}\")\n",
    "print(f\"f1: {f1_score(validation_labels, validation_prediction)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0557056a-e020-4a1a-b059-6bb21f07be07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5000, 768])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e30d83-06fa-4376-8d20-40ddf7c2d008",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "75b70f05-7d80-4590-94bf-1be1ead14a11",
   "metadata": {},
   "source": [
    "## Step 8: Way 2 Use HuggingFace pipeline to get embeddings from pretrained model\n",
    "https://huggingface.co/tasks/feature-extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9259e94-6200-4037-a9b9-7da247392c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = pipeline(\"feature-extraction\", framework=\"pt\", model=\"distilbert/distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a868a64c-3664-4dbb-938f-03d62f976466",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hidden_states = feature_extractor(train_df[\"sentence\"],return_tensors = \"pt\")#[0].numpy().mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8de2c1a-8d62-4785-93ad-40439364561d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hidden_states[0][0].numpy().mean(axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71bde7d-d94c-4290-bf61-faa0ec9d18f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hidden_states[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219ac779-af16-4e74-bbff-b4205c79daf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hidden_states[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5fc8e3-0d5c-4614-b2b8-64da6ed60ce7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f8f1dc-d3ee-44e1-b634-ace2f1742eb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6b23d9-794f-40a0-92b4-22d04a8b883d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "personal_env",
   "language": "python",
   "name": "personal_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
